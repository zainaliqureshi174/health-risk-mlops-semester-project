"""
Federated Learning - Train model across distributed nodes
Using Federated Averaging (FedAvg) algorithm
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score
import pickle
import json
import os

print("="*60)
print("üåê FEDERATED LEARNING TRAINING")
print("="*60)

# Load node configuration
with open('data/federated_nodes/nodes_config.json', 'r') as f:
    nodes_config = json.load(f)

print(f"\nüìä Found {len(nodes_config)} federated nodes")

# Feature columns
feature_cols = ['pm25', 'pm10', 'aqi', 'temperature', 'humidity', 
                'precipitation', 'heart_rate_avg', 'sleep_hours', 
                'spo2', 'stress_level']

# ==========================================
# Federated Averaging Implementation
# ==========================================

def train_local_model(node_data, global_weights=None):
    """Train model on local node data"""
    
    # Node data already has proper binary labels from splitting
    # But we need to reload with actual user-level data
    city = node_data['city'].iloc[0]
    
    # Load original outcomes for this city
    outcomes = pd.read_csv('data/raw/health_outcomes.csv')
    wearable = pd.read_csv('data/raw/wearable_health.csv')
    
    # Filter by city
    city_outcomes = outcomes[outcomes['city'] == city].copy()
    city_wearable = wearable[wearable['city'] == city].copy()
    
    # Merge
    city_outcomes['date'] = pd.to_datetime(city_outcomes['date'])
    city_wearable['date'] = pd.to_datetime(city_wearable['date'])
    
    merged = city_wearable.merge(city_outcomes[['user_id', 'date', 'respiratory_illness']], 
                                  on=['user_id', 'date'], how='inner')
    
    # Add environmental data from node
    merged['date_only'] = merged['date'].dt.date
    node_data['date'] = pd.to_datetime(node_data['date']).dt.date
    
    merged = merged.merge(node_data[['date'] + feature_cols], 
                          left_on='date_only', right_on='date', 
                          how='left', suffixes=('', '_env'))
    
    # Prepare features
    X = merged[feature_cols].dropna()
    y = merged.loc[X.index, 'respiratory_illness'].astype(int)
    
    if len(y.unique()) < 2:
        print(f"    ‚ö†Ô∏è  Warning: Only one class in data, using dummy model")
        return None
    
    # Scale
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train
    model = LogisticRegression(random_state=42, max_iter=1000, warm_start=True)
    
    if global_weights is not None:
        model.coef_ = global_weights['coef']
        model.intercept_ = global_weights['intercept']
        model.classes_ = global_weights['classes']
    
    model.fit(X_scaled, y)
    
    return {
        'coef': model.coef_,
        'intercept': model.intercept_,
        'classes': model.classes_,
        'n_samples': len(X),
        'scaler': scaler
    }

def aggregate_weights(local_models):
    """Federated Averaging - aggregate weights from all nodes"""
    
    total_samples = sum(m['n_samples'] for m in local_models)
    
    # Weighted average of coefficients
    coef_avg = sum(m['coef'] * (m['n_samples'] / total_samples) 
                   for m in local_models)
    
    # Weighted average of intercepts
    intercept_avg = sum(m['intercept'] * (m['n_samples'] / total_samples) 
                       for m in local_models)
    
    return {
        'coef': coef_avg,
        'intercept': intercept_avg,
        'classes': local_models[0]['classes']
    }

# ==========================================
# Federated Training Loop
# ==========================================

print("\n" + "="*60)
print("üîÑ STARTING FEDERATED TRAINING")
print("="*60)

n_rounds = 5  # Number of federated rounds
global_weights = None
round_results = []

for round_num in range(1, n_rounds + 1):
    print(f"\n{'='*40}")
    print(f"ROUND {round_num}/{n_rounds}")
    print(f"{'='*40}")
    
    local_models = []
    
    # Train on each node
    for node_name, node_info in nodes_config.items():
        print(f"\n  Training on {node_name}...")
        
        # Load node data
        node_data = pd.read_csv(node_info['filepath'])
        
        # Train local model
        local_result = train_local_model(node_data, global_weights)
        local_models.append(local_result)
        
        print(f"    ‚úÖ Trained on {local_result['n_samples']} samples")
    
    # Aggregate weights (Federated Averaging)
    print(f"\n  üîó Aggregating weights from {len(local_models)} nodes...")
    global_weights = aggregate_weights(local_models)
    
    print(f"  ‚úÖ Global model updated")
    
    # Evaluate on each node
    print(f"\n  üìä Evaluating on all nodes:")
    accuracies = []
    
    for node_name, node_info in nodes_config.items():
        node_data = pd.read_csv(node_info['filepath'])
        X = node_data[feature_cols].dropna()
        y = node_data.loc[X.index, 'respiratory_illness'].astype(int)
        
        # Use first node's scaler (simplified - in production, use global scaler)
        scaler = local_models[0]['scaler']
        X_scaled = scaler.transform(X)
        
        # Create model with global weights
        model = LogisticRegression()
        model.coef_ = global_weights['coef']
        model.intercept_ = global_weights['intercept']
        model.classes_ = global_weights['classes']
        
        # Evaluate
        y_pred = model.predict(X_scaled)
        acc = accuracy_score(y, y_pred)
        accuracies.append(acc)
        
        print(f"    {node_name}: {acc:.4f}")
    
    avg_accuracy = np.mean(accuracies)
    print(f"\n  üìà Round {round_num} Average Accuracy: {avg_accuracy:.4f}")
    
    round_results.append({
        'round': round_num,
        'avg_accuracy': float(avg_accuracy),
        'node_accuracies': [float(a) for a in accuracies]
    })

# ==========================================
# Save Federated Model
# ==========================================

print("\n" + "="*60)
print("üíæ SAVING FEDERATED MODEL")
print("="*60)

# Create final model
federated_model = LogisticRegression()
federated_model.coef_ = global_weights['coef']
federated_model.intercept_ = global_weights['intercept']
federated_model.classes_ = global_weights['classes']

# Save model
with open('models/federated_model.pkl', 'wb') as f:
    pickle.dump(federated_model, f)
print("‚úÖ Model saved: models/federated_model.pkl")

# Save scaler
with open('models/federated_scaler.pkl', 'wb') as f:
    pickle.dump(local_models[0]['scaler'], f)
print("‚úÖ Scaler saved: models/federated_scaler.pkl")

# Save training history
with open('models/federated_history.json', 'w') as f:
    json.dump(round_results, f, indent=2)
print("‚úÖ Training history saved")

# ==========================================
# Final Evaluation
# ==========================================

print("\n" + "="*60)
print("üìä FINAL FEDERATED MODEL EVALUATION")
print("="*60)

all_predictions = []
all_labels = []

for node_name, node_info in nodes_config.items():
    node_data = pd.read_csv(node_info['filepath'])
    X = node_data[feature_cols].dropna()
    y = node_data.loc[X.index, 'respiratory_illness'].astype(int)
    
    scaler = local_models[0]['scaler']
    X_scaled = scaler.transform(X)
    
    y_pred = federated_model.predict(X_scaled)
    y_proba = federated_model.predict_proba(X_scaled)[:, 1]
    
    all_predictions.extend(y_pred)
    all_labels.extend(y)

final_accuracy = accuracy_score(all_labels, all_predictions)

print(f"\nFinal Federated Model Performance:")
print(f"  Accuracy: {final_accuracy:.4f}")
print(f"  Samples evaluated: {len(all_labels):,}")

# ==========================================
# Compare with Centralized Baseline
# ==========================================

print("\n" + "="*60)
print("‚öñÔ∏è  FEDERATED vs CENTRALIZED COMPARISON")
print("="*60)

# Load baseline results
with open('models/baseline_results.json', 'r') as f:
    baseline_results = json.load(f)

print(f"\nCentralized (Logistic Regression):")
print(f"  Accuracy: {baseline_results['logistic_regression']['accuracy']:.4f}")

print(f"\nFederated (Logistic Regression):")
print(f"  Accuracy: {final_accuracy:.4f}")

print(f"\nDifference: {(final_accuracy - baseline_results['logistic_regression']['accuracy']):.4f}")

print("\n" + "="*60)
print("‚ú® FEDERATED LEARNING COMPLETE!")
print("="*60)
print("\nüéØ Key Achievement: Privacy-preserving distributed learning!")
print("üìä Data remained local to each node")
print("üîê Only model weights were shared, not raw data")
